# Using-Siamese-Networks-to-distinguish-a-Forged-Signature-from-Genuine-Signature
---

## Problem Statement:
---
Signature is one of the most popular and commonly accepted biometric hallmarks that has been used since the ancient times for verifying different entities related to human beings, viz. documents, forms, bank checks, individuals, etc. Therefore, signature verification is a critical task and many efforts have been made to remove the uncertainty involved in the manual authentication procedure, which makes signature verification an important research line in the field of machine learning and pattern recognition.

In this notebook, we model a writer independent signature verification task with a convolutional Siamese network.

---

## About the Dataset:
---
The BHSig260 signature dataset contains the signatures of 260 persons, among them 100 were signed in Bengali and 160 are signed in Hindi.

For each of the signers, 24 genuine and 30 forged signatures are available. This results in 100 × 24 = 2, 400 genuine and 100 × 30 = 3, 000 forged signatures in Bengali, and 160 × 24 = 3, 840 genuine and 160×30 = 4, 800 forged signatures in Hindi.

In this task we are considering only Hindi singatures for easeness.

Paper Link: https://arxiv.org/pdf/1707.02131.pdf

We loaded the dataset to a shared Google Drive path & extracted the same using Google Colaboratory Cloud Platform. The experiment was entirely performed on GCP.

The signatures are initially stored in 160 directories, representing the 160 signatories. Each such directory has 54 signatures, of which the 1st 30 were forged while the remaining 24 were genuine. These were segregated into groups of forged & genuine groups of signatures. The length of each such group was obviously 160, as we were interested in only the Hindi signatures.

These 160 signatures were split into groups of 120, 20, 20 for training, validation & testing respectively.

Each signature image was resized to 155X220 and were grouped into GENUINE-GENUINE & GENUINE-FORGED pairs. These pairs were labelled accordingly with the former being represented as 1, and the latter being represented as 0. For every person we have 24 genuine signatures, hence we have 24 choose 2 = 276 Genuine-Genuine image pairs for one person. To make Genuine-Forged pairs, we pair every Genuine signature of a person with 12 randomly sampled Forged signatures of the same person. Thus we make 24 * 12 = 300 Genuine-Forged image pairs for one person.

In all we have 120 person's data in the training data.

Total no. of Genuine-Genuine pairs = 120 * 276 = 33120

Total number of Genuine-Forged pairs = 120 * 300 = 36000

Total no. of data points = 33120 + 36000 = 69120

---

## Model:
---

We used a custom CNN to build the Siamese Network. This custom CNN was tweaked to result in 3 models, which we have evaluated in this experiment. The o/p of the model was the distance between the embeddings generated by the 2 identical CNNs, when a GENUINE-GENUINE & GENUINE-FORGED signatures are fed to the model. Convolutional layers were used to extract features while Dense Layers were used to generate the aforesaid embeddings from these extracted features. 

Batch size=128
Number of Training Samples = 276*120 + 300*120
Number of Validation Samples = Number of Testing Samples = 276*20 + 300*20

We also used the below Callback functions:

EarlyStopping: stop unnecessary iterations, if the VALIDATION LOSS doesn't DECREASE over 5 ITERATIONS by AT LEAST 0.01 

ReduceLROnPlateau: by a FACTOR of 0.1, if VALIDATION LOSS doesn't DECREASE over 5 ITERATIONS. Keep MINIMUM LEARNING RATE as 0.000001.

ModelCheckpoint: save the best model weights as './signet-bhsig260-model name.h5',  if the VALIDATION LOSS doesn't DECREASE over 5 ITERATIONS by AT LEAST 0.01

---

## Optimisation and Regularisation
---

We used EUCLIDEAN DISTANCE to calculate the distance between the embeddings for two images. The idea is that this distance should be minimal between a GENUINE-GENUINE pair but maximum between GENUINE-FORGED pair of signatures. This is MINIMIZED using a CONTRASTIVE LOSS function.

Source: http://yann.lecun.com/exdb/publis/pdf/hadsell-chopra-lecun-06.pdf

When ytrue is 1, that means the sample are duplicates of each other, so the Euclidean distance (ypred) between their outputs must be minimized. So the loss is taken as the square of that Euclidean distance itself - K.square(y_pred). When ytrue is 0, i.e. the samples are not duplicates, then the Euclidean distance between them must be maximized, at least to the margin. So the loss to be minimized is the difference of the margin and the Euclidean distance - (margin - y_pred).

If the Euclidean distance (ypred) is already greater than the margin, then nothing is to be learned, so the loss is made to be zero in that case by saying K.maximum(margin - y_pred, 0).

We used RMSProp with the below parameters: lr=1e-4, rho=0.9, epsilon=1e-08, as an OPTIMIZER.

---

## Model Training
---

The model was trained in batches of 128 images

---

## Evaluation
---

We computed model TPR & TNR and expressed the model ACCURACY as 0.5 X (TPR + TNR).

With this, we were able to arrive at a best accuracy of 82.7%, with a THRESHOLD of 0.44, i.e. if the if the differnce score is less than 0.44, we predict the test image as Genuine and if the difference score is greater than 0.44, we predict it to be as forged.

---
